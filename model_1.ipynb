{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b76728c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# getting device ready\n",
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9171e1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "data_path=Path('data_ss/')\n",
    "\n",
    "train_dir=data_path/'train'\n",
    "test_dir=data_path/'test'\n",
    "val_dir=data_path/'val'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3c93718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data transformation\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "# taking the best weights for MobileNetV2 model\n",
    "weights = torchvision.models.MobileNet_V2_Weights.DEFAULT\n",
    "\n",
    "# base trasnform from MobileNetV2 model\n",
    "base_transform = weights.transforms()\n",
    "\n",
    "# training transform\n",
    "train_transform = transforms.Compose([\n",
    "\n",
    "    # transforms.RandomPerspective(distortion_scale=0.1, p=0.2),\n",
    "    # transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
    "\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.15, contrast=0.15,\n",
    "                           saturation=0.15, hue=0.05),\n",
    "    base_transform  # best weights of MobileNetV2 model\n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "# test, validation transform\n",
    "# taking the base_transform's value\n",
    "test_val_transform = base_transform\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ca0fe44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=True)\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    RandomRotation(degrees=[-15.0, 15.0], interpolation=nearest, expand=False, fill=0)\n",
      "    ColorJitter(brightness=(0.85, 1.15), contrast=(0.85, 1.15), saturation=(0.85, 1.15), hue=(-0.05, 0.05))\n",
      "    ImageClassification(\n",
      "    crop_size=[224]\n",
      "    resize_size=[232]\n",
      "    mean=[0.485, 0.456, 0.406]\n",
      "    std=[0.229, 0.224, 0.225]\n",
      "    interpolation=InterpolationMode.BILINEAR\n",
      ")\n",
      ")\n",
      "ImageClassification(\n",
      "    crop_size=[224]\n",
      "    resize_size=[232]\n",
      "    mean=[0.485, 0.456, 0.406]\n",
      "    std=[0.229, 0.224, 0.225]\n",
      "    interpolation=InterpolationMode.BILINEAR\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(train_transform)\n",
    "print(test_val_transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2119ac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test, validation data\n",
    "from torchvision import datasets\n",
    "train_data = datasets.ImageFolder(\n",
    "    root=train_dir, transform=train_transform, target_transform=None)\n",
    "test_data = datasets.ImageFolder(\n",
    "    root=test_dir, transform=test_val_transform, target_transform=None)\n",
    "val_data = datasets.ImageFolder(\n",
    "    root=val_dir, transform=test_val_transform, target_transform=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "462b5e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 6744\n",
      "    Root location: data_ss\\train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear, antialias=True)\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               RandomRotation(degrees=[-15.0, 15.0], interpolation=nearest, expand=False, fill=0)\n",
      "               ColorJitter(brightness=(0.85, 1.15), contrast=(0.85, 1.15), saturation=(0.85, 1.15), hue=(-0.05, 0.05))\n",
      "               ImageClassification(\n",
      "               crop_size=[224]\n",
      "               resize_size=[232]\n",
      "               mean=[0.485, 0.456, 0.406]\n",
      "               std=[0.229, 0.224, 0.225]\n",
      "               interpolation=InterpolationMode.BILINEAR\n",
      "           )\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2ad36f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "# batch size and number of classes\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "class_names = train_data.classes\n",
    "# print(len(class_names))\n",
    "# print(class_names)\n",
    "NUM_CLASSES = len(class_names)\n",
    "print(NUM_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26ce8453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test, val dataloaders for model\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=val_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "# with GPU running\n",
    "# add pin_memory=True in train, test, val dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27b6e0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x000002CF475E6A50>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x000002CF47D9C050>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x000002CF47D9C2D0>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataloader)\n",
    "print(test_dataloader)\n",
    "print(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c2462c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (17): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (18): Conv2dNormActivation(\n",
      "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU6(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# MobileNetV2 with Transfer Learning\n",
    "model_MoSE = torchvision.models.mobilenet_v2(weights=weights).to(device=device)\n",
    "print(model_MoSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8867ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=============================================================================================================================\n",
       "Layer (type (var_name))                       Input Shape          Output Shape         Param #              Trainable\n",
       "=============================================================================================================================\n",
       "MobileNetV2 (MobileNetV2)                     [32, 3, 224, 224]    [32, 1000]           --                   True\n",
       "├─Sequential (features)                       [32, 3, 224, 224]    [32, 1280, 7, 7]     --                   True\n",
       "│    └─Conv2dNormActivation (0)               [32, 3, 224, 224]    [32, 32, 112, 112]   --                   True\n",
       "│    │    └─Conv2d (0)                        [32, 3, 224, 224]    [32, 32, 112, 112]   864                  True\n",
       "│    │    └─BatchNorm2d (1)                   [32, 32, 112, 112]   [32, 32, 112, 112]   64                   True\n",
       "│    │    └─ReLU6 (2)                         [32, 32, 112, 112]   [32, 32, 112, 112]   --                   --\n",
       "│    └─InvertedResidual (1)                   [32, 32, 112, 112]   [32, 16, 112, 112]   --                   True\n",
       "│    │    └─Sequential (conv)                 [32, 32, 112, 112]   [32, 16, 112, 112]   896                  True\n",
       "│    └─InvertedResidual (2)                   [32, 16, 112, 112]   [32, 24, 56, 56]     --                   True\n",
       "│    │    └─Sequential (conv)                 [32, 16, 112, 112]   [32, 24, 56, 56]     5,136                True\n",
       "│    └─InvertedResidual (3)                   [32, 24, 56, 56]     [32, 24, 56, 56]     --                   True\n",
       "│    │    └─Sequential (conv)                 [32, 24, 56, 56]     [32, 24, 56, 56]     8,832                True\n",
       "│    └─InvertedResidual (4)                   [32, 24, 56, 56]     [32, 32, 28, 28]     --                   True\n",
       "│    │    └─Sequential (conv)                 [32, 24, 56, 56]     [32, 32, 28, 28]     10,000               True\n",
       "│    └─InvertedResidual (5)                   [32, 32, 28, 28]     [32, 32, 28, 28]     --                   True\n",
       "│    │    └─Sequential (conv)                 [32, 32, 28, 28]     [32, 32, 28, 28]     14,848               True\n",
       "│    └─InvertedResidual (6)                   [32, 32, 28, 28]     [32, 32, 28, 28]     --                   True\n",
       "│    │    └─Sequential (conv)                 [32, 32, 28, 28]     [32, 32, 28, 28]     14,848               True\n",
       "│    └─InvertedResidual (7)                   [32, 32, 28, 28]     [32, 64, 14, 14]     --                   True\n",
       "│    │    └─Sequential (conv)                 [32, 32, 28, 28]     [32, 64, 14, 14]     21,056               True\n",
       "│    └─InvertedResidual (8)                   [32, 64, 14, 14]     [32, 64, 14, 14]     --                   True\n",
       "│    │    └─Sequential (conv)                 [32, 64, 14, 14]     [32, 64, 14, 14]     54,272               True\n",
       "│    └─InvertedResidual (9)                   [32, 64, 14, 14]     [32, 64, 14, 14]     --                   True\n",
       "│    │    └─Sequential (conv)                 [32, 64, 14, 14]     [32, 64, 14, 14]     54,272               True\n",
       "│    └─InvertedResidual (10)                  [32, 64, 14, 14]     [32, 64, 14, 14]     --                   True\n",
       "│    │    └─Sequential (conv)                 [32, 64, 14, 14]     [32, 64, 14, 14]     54,272               True\n",
       "│    └─InvertedResidual (11)                  [32, 64, 14, 14]     [32, 96, 14, 14]     --                   True\n",
       "│    │    └─Sequential (conv)                 [32, 64, 14, 14]     [32, 96, 14, 14]     66,624               True\n",
       "│    └─InvertedResidual (12)                  [32, 96, 14, 14]     [32, 96, 14, 14]     --                   True\n",
       "│    │    └─Sequential (conv)                 [32, 96, 14, 14]     [32, 96, 14, 14]     118,272              True\n",
       "│    └─InvertedResidual (13)                  [32, 96, 14, 14]     [32, 96, 14, 14]     --                   True\n",
       "│    │    └─Sequential (conv)                 [32, 96, 14, 14]     [32, 96, 14, 14]     118,272              True\n",
       "│    └─InvertedResidual (14)                  [32, 96, 14, 14]     [32, 160, 7, 7]      --                   True\n",
       "│    │    └─Sequential (conv)                 [32, 96, 14, 14]     [32, 160, 7, 7]      155,264              True\n",
       "│    └─InvertedResidual (15)                  [32, 160, 7, 7]      [32, 160, 7, 7]      --                   True\n",
       "│    │    └─Sequential (conv)                 [32, 160, 7, 7]      [32, 160, 7, 7]      320,000              True\n",
       "│    └─InvertedResidual (16)                  [32, 160, 7, 7]      [32, 160, 7, 7]      --                   True\n",
       "│    │    └─Sequential (conv)                 [32, 160, 7, 7]      [32, 160, 7, 7]      320,000              True\n",
       "│    └─InvertedResidual (17)                  [32, 160, 7, 7]      [32, 320, 7, 7]      --                   True\n",
       "│    │    └─Sequential (conv)                 [32, 160, 7, 7]      [32, 320, 7, 7]      473,920              True\n",
       "│    └─Conv2dNormActivation (18)              [32, 320, 7, 7]      [32, 1280, 7, 7]     --                   True\n",
       "│    │    └─Conv2d (0)                        [32, 320, 7, 7]      [32, 1280, 7, 7]     409,600              True\n",
       "│    │    └─BatchNorm2d (1)                   [32, 1280, 7, 7]     [32, 1280, 7, 7]     2,560                True\n",
       "│    │    └─ReLU6 (2)                         [32, 1280, 7, 7]     [32, 1280, 7, 7]     --                   --\n",
       "├─Sequential (classifier)                     [32, 1280]           [32, 1000]           --                   True\n",
       "│    └─Dropout (0)                            [32, 1280]           [32, 1280]           --                   --\n",
       "│    └─Linear (1)                             [32, 1280]           [32, 1000]           1,281,000            True\n",
       "=============================================================================================================================\n",
       "Total params: 3,504,872\n",
       "Trainable params: 3,504,872\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 9.63\n",
       "=============================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 3419.45\n",
       "Params size (MB): 14.02\n",
       "Estimated Total Size (MB): 3452.74\n",
       "============================================================================================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "from torchinfo import summary\n",
    "summary(model=model_MoSE, input_size=(32, 3, 224, 224),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb4d188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding for more efficiency improvment\n",
    "# adding SE block\n",
    "# This is an attention mechanism that helps the model weight which channels of the features are most relevant.\n",
    "\n",
    "class SEBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels, reduction_ratio=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.avg_pool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_channels, in_channels //\n",
    "                            reduction_ratio, bias=False),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(in_channels // reduction_ratio,\n",
    "                            in_channels, bias=False),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)  # Squeeze operation\n",
    "        y = self.fc(y).view(b, c, 1, 1)  # Excitation operation\n",
    "        return x * y.expand_as(x)  # Scale the input features\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a737854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping base model in feature excitation mode\n",
    "for param in model_MoSE.parameters():\n",
    "    param.requires_grad=False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ef180ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding SE block before final classifier of MobileNetV2 model\n",
    "# last feature of MobileNetV2 model has output_channels = 1280\n",
    "model_MoSE.features.add_module('se_block_custom', SEBlock(\n",
    "    in_channels=1280, reduction_ratio=16))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20194ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the output classifier\n",
    "torch.manual_seed(42)\n",
    "model_MoSE.classifier = torch.nn.Sequential(\n",
    "\n",
    "    torch.nn.Dropout(p=0.3, inplace=True),\n",
    "    torch.nn.Linear(in_features=1280, out_features=NUM_CLASSES,\n",
    "                    bias=True).to(device=device)\n",
    ")\n",
    "\n",
    "model_MoSE.classifier = model_MoSE.classifier.to(device=device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58d0c640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=============================================================================================================================\n",
       "Layer (type (var_name))                       Input Shape          Output Shape         Param #              Trainable\n",
       "=============================================================================================================================\n",
       "MobileNetV2 (MobileNetV2)                     [32, 3, 224, 224]    [32, 23]             --                   Partial\n",
       "├─Sequential (features)                       [32, 3, 224, 224]    [32, 1280, 7, 7]     --                   Partial\n",
       "│    └─Conv2dNormActivation (0)               [32, 3, 224, 224]    [32, 32, 112, 112]   --                   False\n",
       "│    │    └─Conv2d (0)                        [32, 3, 224, 224]    [32, 32, 112, 112]   (864)                False\n",
       "│    │    └─BatchNorm2d (1)                   [32, 32, 112, 112]   [32, 32, 112, 112]   (64)                 False\n",
       "│    │    └─ReLU6 (2)                         [32, 32, 112, 112]   [32, 32, 112, 112]   --                   --\n",
       "│    └─InvertedResidual (1)                   [32, 32, 112, 112]   [32, 16, 112, 112]   --                   False\n",
       "│    │    └─Sequential (conv)                 [32, 32, 112, 112]   [32, 16, 112, 112]   (896)                False\n",
       "│    └─InvertedResidual (2)                   [32, 16, 112, 112]   [32, 24, 56, 56]     --                   False\n",
       "│    │    └─Sequential (conv)                 [32, 16, 112, 112]   [32, 24, 56, 56]     (5,136)              False\n",
       "│    └─InvertedResidual (3)                   [32, 24, 56, 56]     [32, 24, 56, 56]     --                   False\n",
       "│    │    └─Sequential (conv)                 [32, 24, 56, 56]     [32, 24, 56, 56]     (8,832)              False\n",
       "│    └─InvertedResidual (4)                   [32, 24, 56, 56]     [32, 32, 28, 28]     --                   False\n",
       "│    │    └─Sequential (conv)                 [32, 24, 56, 56]     [32, 32, 28, 28]     (10,000)             False\n",
       "│    └─InvertedResidual (5)                   [32, 32, 28, 28]     [32, 32, 28, 28]     --                   False\n",
       "│    │    └─Sequential (conv)                 [32, 32, 28, 28]     [32, 32, 28, 28]     (14,848)             False\n",
       "│    └─InvertedResidual (6)                   [32, 32, 28, 28]     [32, 32, 28, 28]     --                   False\n",
       "│    │    └─Sequential (conv)                 [32, 32, 28, 28]     [32, 32, 28, 28]     (14,848)             False\n",
       "│    └─InvertedResidual (7)                   [32, 32, 28, 28]     [32, 64, 14, 14]     --                   False\n",
       "│    │    └─Sequential (conv)                 [32, 32, 28, 28]     [32, 64, 14, 14]     (21,056)             False\n",
       "│    └─InvertedResidual (8)                   [32, 64, 14, 14]     [32, 64, 14, 14]     --                   False\n",
       "│    │    └─Sequential (conv)                 [32, 64, 14, 14]     [32, 64, 14, 14]     (54,272)             False\n",
       "│    └─InvertedResidual (9)                   [32, 64, 14, 14]     [32, 64, 14, 14]     --                   False\n",
       "│    │    └─Sequential (conv)                 [32, 64, 14, 14]     [32, 64, 14, 14]     (54,272)             False\n",
       "│    └─InvertedResidual (10)                  [32, 64, 14, 14]     [32, 64, 14, 14]     --                   False\n",
       "│    │    └─Sequential (conv)                 [32, 64, 14, 14]     [32, 64, 14, 14]     (54,272)             False\n",
       "│    └─InvertedResidual (11)                  [32, 64, 14, 14]     [32, 96, 14, 14]     --                   False\n",
       "│    │    └─Sequential (conv)                 [32, 64, 14, 14]     [32, 96, 14, 14]     (66,624)             False\n",
       "│    └─InvertedResidual (12)                  [32, 96, 14, 14]     [32, 96, 14, 14]     --                   False\n",
       "│    │    └─Sequential (conv)                 [32, 96, 14, 14]     [32, 96, 14, 14]     (118,272)            False\n",
       "│    └─InvertedResidual (13)                  [32, 96, 14, 14]     [32, 96, 14, 14]     --                   False\n",
       "│    │    └─Sequential (conv)                 [32, 96, 14, 14]     [32, 96, 14, 14]     (118,272)            False\n",
       "│    └─InvertedResidual (14)                  [32, 96, 14, 14]     [32, 160, 7, 7]      --                   False\n",
       "│    │    └─Sequential (conv)                 [32, 96, 14, 14]     [32, 160, 7, 7]      (155,264)            False\n",
       "│    └─InvertedResidual (15)                  [32, 160, 7, 7]      [32, 160, 7, 7]      --                   False\n",
       "│    │    └─Sequential (conv)                 [32, 160, 7, 7]      [32, 160, 7, 7]      (320,000)            False\n",
       "│    └─InvertedResidual (16)                  [32, 160, 7, 7]      [32, 160, 7, 7]      --                   False\n",
       "│    │    └─Sequential (conv)                 [32, 160, 7, 7]      [32, 160, 7, 7]      (320,000)            False\n",
       "│    └─InvertedResidual (17)                  [32, 160, 7, 7]      [32, 320, 7, 7]      --                   False\n",
       "│    │    └─Sequential (conv)                 [32, 160, 7, 7]      [32, 320, 7, 7]      (473,920)            False\n",
       "│    └─Conv2dNormActivation (18)              [32, 320, 7, 7]      [32, 1280, 7, 7]     --                   False\n",
       "│    │    └─Conv2d (0)                        [32, 320, 7, 7]      [32, 1280, 7, 7]     (409,600)            False\n",
       "│    │    └─BatchNorm2d (1)                   [32, 1280, 7, 7]     [32, 1280, 7, 7]     (2,560)              False\n",
       "│    │    └─ReLU6 (2)                         [32, 1280, 7, 7]     [32, 1280, 7, 7]     --                   --\n",
       "│    └─SEBlock (se_block_custom)              [32, 1280, 7, 7]     [32, 1280, 7, 7]     --                   True\n",
       "│    │    └─AdaptiveAvgPool2d (avg_pool)      [32, 1280, 7, 7]     [32, 1280, 1, 1]     --                   --\n",
       "│    │    └─Sequential (fc)                   [32, 1280]           [32, 1280]           204,800              True\n",
       "├─Sequential (classifier)                     [32, 1280]           [32, 23]             --                   True\n",
       "│    └─Dropout (0)                            [32, 1280]           [32, 1280]           --                   --\n",
       "│    └─Linear (1)                             [32, 1280]           [32, 23]             29,463               True\n",
       "=============================================================================================================================\n",
       "Total params: 2,458,135\n",
       "Trainable params: 234,263\n",
       "Non-trainable params: 2,223,872\n",
       "Total mult-adds (Units.GIGABYTES): 9.59\n",
       "=============================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 3419.55\n",
       "Params size (MB): 9.83\n",
       "Estimated Total Size (MB): 3448.65\n",
       "============================================================================================================================="
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary of new model\n",
    "# MobileNetV2 with SE block\n",
    "\n",
    "summary(model=model_MoSE, input_size=(32, 3, 224, 224),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d71b4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function for model_mobnetv2\n",
    "from torch import nn\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimization function\n",
    "optimizer_fn = torch.optim.Adam(\n",
    "    params=model_MoSE.parameters(), lr=0.0005, weight_decay=1e-5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "542e29a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING STEP\n",
    "\n",
    "from torchmetrics.classification import MulticlassAccuracy, MulticlassPrecision, MulticlassRecall, MulticlassF1Score\n",
    "\n",
    "\n",
    "def train_step(model: nn.Module,\n",
    "               train_dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: nn.modules,\n",
    "               optimizer_fn: torch.optim.Optimizer,\n",
    "               device: torch.device = device\n",
    "               ):\n",
    "    # model -> train\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    metric_accuracy = MulticlassAccuracy(\n",
    "        num_classes=NUM_CLASSES, average='macro').to(device)\n",
    "\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        y_pred = model(X)  # forward pass\n",
    "        loss = loss_fn(y_pred, y)  # loss\n",
    "        train_loss += loss.item()\n",
    "        optimizer_fn.zero_grad()  # zero grad\n",
    "        loss.backward()  # back propagation\n",
    "        optimizer_fn.step()  # updation\n",
    "\n",
    "        # calculate and accumulate accuracy metrics across all batches\n",
    "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "        metric_accuracy.update(y_pred_class, y)\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_accuracy = metric_accuracy.compute().item()\n",
    "    return train_loss, train_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d6fd787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING STEP\n",
    "def test_step(model: nn.Module,\n",
    "              test_dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: nn.Module,\n",
    "              device: torch.device = device\n",
    "              ):\n",
    "\n",
    "    # model -> testing\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "\n",
    "    # test_accuracy = 0\n",
    "    average_type = 'weighted'\n",
    "    metric_accuracy = MulticlassAccuracy(\n",
    "        num_classes=NUM_CLASSES, average=average_type).to(device)\n",
    "    metric_precision = MulticlassPrecision(\n",
    "        num_classes=NUM_CLASSES, average=average_type, zero_division=0).to(device)\n",
    "    metric_recall = MulticlassRecall(\n",
    "        num_classes=NUM_CLASSES, average=average_type, zero_division=0).to(device)\n",
    "    metric_f1 = MulticlassF1Score(\n",
    "        num_classes=NUM_CLASSES, average=average_type, zero_division=0).to(device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X, y) in enumerate(test_dataloader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            test_pred = model(X)  # forward pass\n",
    "            loss = loss_fn(test_pred, y)  # loss function\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Calculate and accumulate accuracy\n",
    "            test_pred_labels = test_pred.argmax(dim=1)\n",
    "\n",
    "            metric_accuracy.update(test_pred_labels, y)\n",
    "            metric_precision.update(test_pred_labels, y)\n",
    "            metric_recall.update(test_pred_labels, y)\n",
    "            metric_f1.update(test_pred_labels, y)\n",
    "\n",
    "    test_loss /= len(test_dataloader)\n",
    "    metrics = {\n",
    "        'test_accuracy': metric_accuracy.compute().item(),\n",
    "        'test_precision': metric_precision.compute().item(),\n",
    "        'test_recall': metric_recall.compute().item(),\n",
    "        'test_f1_score': metric_f1.compute().item()\n",
    "    }\n",
    "\n",
    "    return test_loss, metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42c0ba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION STEP\n",
    "def val_step(model: nn.Module,\n",
    "             val_dataloader: torch.utils.data.DataLoader,\n",
    "             loss_fn: nn.Module,\n",
    "             device: torch.device = device\n",
    "             ):\n",
    "    # model -> testing\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "\n",
    "    metric_accuracy = MulticlassAccuracy(\n",
    "        num_classes=NUM_CLASSES, average='macro').to(device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X, y in val_dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            val_pred = model(X)\n",
    "            loss = loss_fn(val_pred, y)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            val_pred_labels = val_pred.argmax(dim=1)\n",
    "            metric_accuracy.update(val_pred_labels, y)\n",
    "\n",
    "    val_loss /= len(val_dataloader)\n",
    "    val_accuracy = metric_accuracy.compute().item()\n",
    "    return val_loss, val_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eccf2cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\PyTorch\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# model_mobnetv2 TRAINING\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def model_train(model: nn.Module,\n",
    "                train_dataloader: torch.utils.data.DataLoader,\n",
    "                val_dataloader: torch.utils.data.DataLoader,  # ADDED\n",
    "                test_dataloader: torch.utils.data.DataLoader,\n",
    "                loss_fn: nn.Module,\n",
    "                optimizer_fn: torch.optim.Optimizer,\n",
    "                epochs: int,\n",
    "                device: torch.device = device\n",
    "                ):\n",
    "\n",
    "    results = {\n",
    "        'train_loss': [], 'train_accuracy': [],\n",
    "        'val_loss': [], 'val_accuracy': [],\n",
    "        'test_loss': [], 'test_accuracy': [],\n",
    "        'test_precision': [], 'test_recall': [], 'test_f1_score': []\n",
    "    }\n",
    "\n",
    "    best_val_accuracy = 0.0  # best validation accuracy\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc=\"Training Epochs\"):\n",
    "        train_loss, train_accuracy = train_step(\n",
    "            model, train_dataloader, loss_fn, optimizer_fn, device)\n",
    "        val_loss, val_accuracy = val_step(\n",
    "            model, val_dataloader, loss_fn, device)\n",
    "        test_loss, test_metrics = test_step(\n",
    "            model, test_dataloader, loss_fn, device)\n",
    "\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1:02d} | \"\n",
    "            f\"Loss: {train_loss:.4f} | Acc: {train_accuracy:.4f} | \"\n",
    "            f\"Val Loss: {val_loss:.4f} | Val Acc: {val_accuracy:.4f} | \"\n",
    "            f\"Test Accuracy: {test_metrics['test_accuracy']:.4f} |\"\n",
    "            f\"Test Recall: {test_metrics['test_recall']:.4f} |\"\n",
    "            f\"Test Precision: {test_metrics['test_precision']:.4f} |\"\n",
    "            f\"Test F1: {test_metrics['test_f1_score']:.4f}\"\n",
    "        )\n",
    "\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "\n",
    "            # additional step to save model on best val_accuracy\n",
    "            # torch.save(model.state_dict(), f'best_model_epoch_{epoch+1}.pth')\n",
    "            # print(\"SAVED BEST MODEL\")\n",
    "\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_accuracy\"].append(train_accuracy)\n",
    "        results[\"val_loss\"].append(val_loss)\n",
    "        results[\"val_accuracy\"].append(val_accuracy)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_accuracy\"].append(test_metrics['test_accuracy'])\n",
    "        results[\"test_precision\"].append(test_metrics['test_precision'])\n",
    "        results[\"test_recall\"].append(test_metrics['test_recall'])\n",
    "        results[\"test_f1_score\"].append(test_metrics['test_f1_score'])\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ce3ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_moSE_results = model_train(model=model_MoSE,\n",
    "                                 train_dataloader=train_dataloader,\n",
    "                                 val_dataloader=val_dataloader,\n",
    "                                 test_dataloader=test_dataloader,\n",
    "                                 loss_fn=loss_fn,\n",
    "                                 optimizer_fn=optimizer_fn,\n",
    "                                 epochs=50,\n",
    "                                 device=device\n",
    "                                 )\n",
    "\n",
    "model_moSE_results\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
